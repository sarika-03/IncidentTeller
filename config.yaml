# IncidentTeller Configuration
# Production-ready configuration example

server:
  host: "0.0.0.0"
  port: 8080
  read_timeout: "30s"
  write_timeout: "30s"
  idle_timeout: "120s"

netdata:
  # Local Netdata Agent (default)
  cloud_enabled: false
  base_url: "http://localhost:19999"
  hostname: "localhost"
  
  # OR Netdata Cloud (uncomment to use)
  # cloud_enabled: true
  # cloud_token: "your-netdata-cloud-token-here"
  # cloud_space: "your-space-id"
  # cloud_rooms: ["room-id-1", "room-id-2"]  # Optional: specific rooms
  
  timeout: "30s"
  retry_count: 3
  retry_delay: "1s"
  poll_interval: "10s"
  batch_size: 100

ai:
  enabled: true
  model_type: "local"
  confidence_threshold: 0.7
  max_predictions: 5
  prediction_timeout: "10s"
  enable_learning: false
  model_path: "./models"
  # For external AI service:
  # api_token: "your-api-token"
  # api_endpoint: "https://api.openai.com/v1"

database:
  type: "sqlite"
  host: "localhost"
  port: 5432
  database: "incident_teller"
  username: "incident_teller"
  password: "secure-password"
  ssl_mode: "disable"
  max_connections: 10
  max_idle_conns: 5
  conn_max_lifetime: "1h"
  sqlite_path: "./incident_teller.db"

observability:
  log_level: "info"
  log_format: "json"
  enable_metrics: true
  metrics_port: 9090
  enable_tracing: false
  tracing_endpoint: ""
  service_name: "incident-teller"
  service_version: "1.0.0"
  tags:
    environment: "production"
    team: "sre"

incident:
  correlation_window: "15m"
  incident_timeout: "24h"
  max_incidents: 1000
  enable_auto_resolve: true
  resolve_threshold: "30m"
  enable_alert_dedup: true
  dedup_window: "5m"